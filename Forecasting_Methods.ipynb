{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import DateType\n",
    "from datetime import date, timedelta\n",
    "import datetime as dt\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.sql.functions import col, avg, sum\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log4jLogger = sc._jvm.org.apache.log4j\n",
    "LOGGER = log4jLogger.LogManager.getLogger(__name__)\n",
    "LOGGER.error(\"pyspark script logger initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Feature File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://172.16.27.208:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://172.16.27.208:7077 appName=spark>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.stop()\n",
    "sc = pyspark.SparkContext(master=\"spark://172.16.27.208:7077\",appName=\"spark\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(sc.getConf().get(\"spark.default.parallelism\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/test5/Desktop/smart-meters-in-london/Feature_file/\"\n",
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for mth in range(1,13):\n",
    "    month_df = sqlcontext.read.csv(base_path+\"Cleaned_2013_Features_mth_{}.csv\".format(mth),header = True,inferSchema=True,)\n",
    "    if mth == 1:\n",
    "        df = sqlcontext.createDataFrame(df,month_df.schema)\n",
    "    df = df.union(month_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(480,\"LCLid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LCLid: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- energy(kWh/h): double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- weekDay: string (nullable = true)\n",
      " |-- 1_diff_energy_t_0: double (nullable = true)\n",
      " |-- 2_diff_energy_t_0: double (nullable = true)\n",
      " |-- 1_diff_energy_t_1: double (nullable = true)\n",
      " |-- 2_diff_energy_t_1: double (nullable = true)\n",
      " |-- 1_diff_energy_t_2: double (nullable = true)\n",
      " |-- 2_diff_energy_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_1: double (nullable = true)\n",
      " |-- diff_energy_week_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_3: double (nullable = true)\n",
      " |-- diff_energy_week_t_4: double (nullable = true)\n",
      " |-- mean_1: double (nullable = true)\n",
      " |-- mean_2: double (nullable = true)\n",
      " |-- min_1: double (nullable = true)\n",
      " |-- max_1: double (nullable = true)\n",
      " |-- min_2: double (nullable = true)\n",
      " |-- max_2: double (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- windBearing: integer (nullable = true)\n",
      " |-- dewPoint: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- windSpeed: double (nullable = true)\n",
      " |-- precipType: string (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- date2: timestamp (nullable = true)\n",
      " |-- temperatureMax: double (nullable = true)\n",
      " |-- temperatureMin: double (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- Weekday/end: integer (nullable = true)\n",
      " |-- stdorToU: string (nullable = true)\n",
      " |-- Acorn_grouped: string (nullable = true)\n",
      " |-- weekDay_index: double (nullable = true)\n",
      " |-- precipType_index: double (nullable = true)\n",
      " |-- summary_index: double (nullable = true)\n",
      " |-- stdorToU_index: double (nullable = true)\n",
      " |-- Acorn_grouped_index: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(\"_c0\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disaggregated Approach using RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform :\n",
    "    * 1 hot encoding\n",
    "    * Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LCLid: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- energy(kWh/h): double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- weekDay: string (nullable = true)\n",
      " |-- 1_diff_energy_t_0: double (nullable = true)\n",
      " |-- 2_diff_energy_t_0: double (nullable = true)\n",
      " |-- 1_diff_energy_t_1: double (nullable = true)\n",
      " |-- 2_diff_energy_t_1: double (nullable = true)\n",
      " |-- 1_diff_energy_t_2: double (nullable = true)\n",
      " |-- 2_diff_energy_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_1: double (nullable = true)\n",
      " |-- diff_energy_week_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_3: double (nullable = true)\n",
      " |-- diff_energy_week_t_4: double (nullable = true)\n",
      " |-- mean_1: double (nullable = true)\n",
      " |-- mean_2: double (nullable = true)\n",
      " |-- min_1: double (nullable = true)\n",
      " |-- max_1: double (nullable = true)\n",
      " |-- min_2: double (nullable = true)\n",
      " |-- max_2: double (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- windBearing: integer (nullable = true)\n",
      " |-- dewPoint: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- windSpeed: double (nullable = true)\n",
      " |-- precipType: string (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- date2: timestamp (nullable = true)\n",
      " |-- temperatureMax: double (nullable = true)\n",
      " |-- temperatureMin: double (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- Weekday/end: integer (nullable = true)\n",
      " |-- stdorToU: string (nullable = true)\n",
      " |-- Acorn_grouped: string (nullable = true)\n",
      " |-- weekDay_index: double (nullable = true)\n",
      " |-- precipType_index: double (nullable = true)\n",
      " |-- summary_index: double (nullable = true)\n",
      " |-- stdorToU_index: double (nullable = true)\n",
      " |-- Acorn_grouped_index: double (nullable = true)\n",
      " |-- category_weekDay_index: vector (nullable = true)\n",
      " |-- category_precipType_index: vector (nullable = true)\n",
      " |-- category_summary_index: vector (nullable = true)\n",
      " |-- category_stdorToU_index: vector (nullable = true)\n",
      " |-- category_Acorn_grouped_index: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputCols = [\"weekDay_index\",\"precipType_index\",\"summary_index\",\"stdorToU_index\",\"Acorn_grouped_index\"]\n",
    "df_encoded = df\n",
    "for col in outputCols: \n",
    "    encoder = OneHotEncoder(inputCol=col, outputCol=\"category_{}\".format(col))\n",
    "    df_encoded = encoder.transform(df_encoded).cache()\n",
    "df_encoded.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputCols = [\"weekDay\",\"precipType\",\"summary\",\"stdorToU\",\"Acorn_grouped\",\"count\"]\n",
    "columns = df_encoded.columns\n",
    "feature_col = columns[4:]\n",
    "feature_col.append(columns[2])\n",
    "feature_col = set(feature_col) - set(inputCols)\n",
    "feature_col = feature_col - set(outputCols)\n",
    "feature_col = list(feature_col)\n",
    "feature_col.remove(\"date2\")\n",
    "len(feature_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping row with Na\n",
    "df_encoded = df_encoded.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(LCLid='MAC000439', date=datetime.datetime(2013, 1, 1, 0, 0), hour=0, energy(kWh/h)=0.684, month=1, weekDay='Tue', 1_diff_energy_t_0=0.804, 2_diff_energy_t_0=0.828, 1_diff_energy_t_1=0.928, 2_diff_energy_t_1=0.858, 1_diff_energy_t_2=0.871, 2_diff_energy_t_2=1.055, diff_energy_week_t_1=0.7, diff_energy_week_t_2=0.714, diff_energy_week_t_3=0.835, diff_energy_week_t_4=0.841, mean_1=0.6039166666666668, mean_2=0.5401666666666667, min_1=0.191, max_1=1.542, min_2=0.186, max_2=1.438, count=8760, visibility=13.28, windBearing=269, dewPoint=2.6, pressure=1008.19, apparentTemperature=3.66, windSpeed=5.46, precipType='rain', humidity=0.73, summary='Partly Cloudy', date2=datetime.datetime(2013, 1, 1, 0, 0), temperatureMax=7.49, temperatureMin=3.31, holiday=1, Weekday/end=0, stdorToU='ToU', Acorn_grouped='Comfortable', weekDay_index=4.0, precipType_index=0.0, summary_index=2.0, stdorToU_index=1.0, Acorn_grouped_index=2.0, category_weekDay_index=SparseVector(6, {4: 1.0}), category_precipType_index=SparseVector(1, {0: 1.0}), category_summary_index=SparseVector(11, {2: 1.0}), category_stdorToU_index=SparseVector(1, {}), category_Acorn_grouped_index=SparseVector(2, {}), features=SparseVector(50, {0: 0.73, 5: 1.0, 7: 5.46, 8: 0.7, 9: 1008.19, 10: 0.841, 11: 0.6039, 13: 0.871, 14: 1.0, 15: 1.542, 18: 0.5402, 19: 0.191, 20: 1.0, 23: 1.0, 32: 0.186, 33: 0.714, 34: 3.31, 37: 0.835, 38: 13.28, 39: 1.055, 40: 0.928, 41: 269.0, 42: 2.6, 43: 0.828, 44: 0.804, 45: 1.438, 46: 3.66, 47: 7.49, 48: 1.0, 49: 0.858}))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=feature_col, outputCol=\"features\")\n",
    "df_feature = vecAssembler.transform(df_encoded)\n",
    "df_feature.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LCLid: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- weekDay: string (nullable = true)\n",
      " |-- 1_diff_energy_t_0: double (nullable = true)\n",
      " |-- 2_diff_energy_t_0: double (nullable = true)\n",
      " |-- 1_diff_energy_t_1: double (nullable = true)\n",
      " |-- 2_diff_energy_t_1: double (nullable = true)\n",
      " |-- 1_diff_energy_t_2: double (nullable = true)\n",
      " |-- 2_diff_energy_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_1: double (nullable = true)\n",
      " |-- diff_energy_week_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_3: double (nullable = true)\n",
      " |-- diff_energy_week_t_4: double (nullable = true)\n",
      " |-- mean_1: double (nullable = true)\n",
      " |-- mean_2: double (nullable = true)\n",
      " |-- min_1: double (nullable = true)\n",
      " |-- max_1: double (nullable = true)\n",
      " |-- min_2: double (nullable = true)\n",
      " |-- max_2: double (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- windBearing: integer (nullable = true)\n",
      " |-- dewPoint: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- windSpeed: double (nullable = true)\n",
      " |-- precipType: string (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- date2: timestamp (nullable = true)\n",
      " |-- temperatureMax: double (nullable = true)\n",
      " |-- temperatureMin: double (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- Weekday/end: integer (nullable = true)\n",
      " |-- stdorToU: string (nullable = true)\n",
      " |-- Acorn_grouped: string (nullable = true)\n",
      " |-- weekDay_index: double (nullable = true)\n",
      " |-- precipType_index: double (nullable = true)\n",
      " |-- summary_index: double (nullable = true)\n",
      " |-- stdorToU_index: double (nullable = true)\n",
      " |-- Acorn_grouped_index: double (nullable = true)\n",
      " |-- category_weekDay_index: vector (nullable = true)\n",
      " |-- category_precipType_index: vector (nullable = true)\n",
      " |-- category_summary_index: vector (nullable = true)\n",
      " |-- category_stdorToU_index: vector (nullable = true)\n",
      " |-- category_Acorn_grouped_index: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_feature = df_feature.withColumnRenamed(\"energy(kWh/h)\",\"label\")\n",
    "df_feature = df_feature.withColumn(\"date\",df_feature[\"date\"].cast(DateType()))\n",
    "df_feature.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  actual and Predicted for given day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregate(df):\n",
    "    list = [\"date\",\"hour\"]\n",
    "    df = df.groupBy(list).agg(sum(\"label\"),sum(\"prediction\"))    \n",
    "    return df\n",
    "\n",
    "def select_predicted_actual(df,date,LCLid=None):\n",
    "    list = []\n",
    "    if LCLid != None:\n",
    "        list = df.where((df[\"LCLid\"] == LCLid) & (df[\"date\"] == date)).select(\"label\",\"prediction\").collect()\n",
    "    else:\n",
    "        list = df.where((df[\"date\"] == date)).select(\"label\",\"prediction\").collect()\n",
    "    actual = [int(row['label']) for row in list]\n",
    "    predicted = [int(row['prediction']) for row in list]\n",
    "    return actual,predicted\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.sqrt(np.mean(np.abs((y_true - y_pred)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_point = 28641840, Test_point = 5753520\n"
     ]
    }
   ],
   "source": [
    "train_df = df_feature.where(df_feature[\"date\"] <= date(2013,10,31))\n",
    "test_df = df_feature.where(df_feature[\"date\"] > date(2013,10,31))# & (df_feature[\"date\"] <= date(2013,1,2)))\n",
    "#plits = train_df.randomSplit([0.01, 0.01,0.98], 24)\n",
    "#splits[0].count()\n",
    "\n",
    "print(\"Train_point = {}, Test_point = {}\".format(train_df.count(),test_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(seed=123)\n",
    "# paramGrid = ParamGridBuilder()\\\n",
    "#     .addGrid(rf.numTrees,[10,20,50]) \\\n",
    "#     .addGrid(rf.maxDepth,[10,15,20])\\\n",
    "#     .addGrid(rf.maxBins,[64,128])\\\n",
    "#     .addGrid(rf.featureSubsetStrategy,[\"auto\",\"sqrt\"])\\\n",
    "#     .build()\n",
    "# tvs = TrainValidationSplit(estimator=rf,\n",
    "#                            estimatorParamMaps=paramGrid,\n",
    "#                            evaluator=RegressionEvaluator(),\n",
    "#                            # 80% of the data will be used for training, 20% for validation.\n",
    "#                            trainRatio=0.8)\n",
    "# model = tvs.fit(train_df)\n",
    "\n",
    "## Execute this \n",
    "rf = RandomForestRegressor(numTrees=20,maxDepth=10,maxBins=128,seed=4)\n",
    "model = rf.fit(train_df)\n",
    "best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(base_path+\"rf_model_bin128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model.bestModel\n",
    "print(\" RF optimal num_trees = {}\".format(best_model.getNumTrees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "{param[0].name: param[1] for param in best_model.extractParamMap().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_val = best_model.transform(test_df)\n",
    "pred_val.printSchema()\n",
    "evaluator = RegressionEvaluator(labelCol='label', predictionCol='prediction', metricName=\"rmse\")\n",
    "accuracy = evaluator.evaluate(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbt = GBTRegressor(seed=123)\n",
    "# paramGrid = ParamGridBuilder()\\\n",
    "#     .addGrid(gbt.maxIter,[10,20,50]) \\\n",
    "#     .addGrid(gbt.maxDepth,[10,15,20])\\\n",
    "#     .addGrid(gbt.maxBins,[64,128])\\\n",
    "#     .build()\n",
    "# tvs = TrainValidationSplit(estimator=gbt,\n",
    "#                            estimatorParamMaps=paramGrid,\n",
    "#                            evaluator=RegressionEvaluator(),\n",
    "#                            # 80% of the data will be used for training, 20% for validation.\n",
    "#                            trainRatio=0.8)\n",
    "# gbt_model = tvs.fit(splits[0])\n",
    "\n",
    "## Execute this \n",
    "gbt = GBTRegressor(maxBins=128,maxDepth=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "best_model = gbt_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model.save(base_path+\"gbt_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cacheNodeIds': False,\n",
       " 'checkpointInterval': 10,\n",
       " 'featuresCol': 'features',\n",
       " 'impurity': 'variance',\n",
       " 'labelCol': 'label',\n",
       " 'lossType': 'squared',\n",
       " 'maxBins': 128,\n",
       " 'maxDepth': 10,\n",
       " 'maxIter': 10,\n",
       " 'maxMemoryInMB': 256,\n",
       " 'minInfoGain': 0.0,\n",
       " 'minInstancesPerNode': 1,\n",
       " 'predictionCol': 'prediction',\n",
       " 'seed': 123,\n",
       " 'stepSize': 0.1,\n",
       " 'subsamplingRate': 1.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{param[0].name: param[1] for param in gbt_model.bestModel.extractParamMap().items()}\n",
    "best_model = gbt_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LCLid: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- weekDay: string (nullable = true)\n",
      " |-- 1_diff_energy_t_0: double (nullable = true)\n",
      " |-- 2_diff_energy_t_0: double (nullable = true)\n",
      " |-- 1_diff_energy_t_1: double (nullable = true)\n",
      " |-- 2_diff_energy_t_1: double (nullable = true)\n",
      " |-- 1_diff_energy_t_2: double (nullable = true)\n",
      " |-- 2_diff_energy_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_1: double (nullable = true)\n",
      " |-- diff_energy_week_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_3: double (nullable = true)\n",
      " |-- diff_energy_week_t_4: double (nullable = true)\n",
      " |-- mean_1: double (nullable = true)\n",
      " |-- mean_2: double (nullable = true)\n",
      " |-- min_1: double (nullable = true)\n",
      " |-- max_1: double (nullable = true)\n",
      " |-- min_2: double (nullable = true)\n",
      " |-- max_2: double (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- windBearing: integer (nullable = true)\n",
      " |-- dewPoint: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- windSpeed: double (nullable = true)\n",
      " |-- precipType: string (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- date2: timestamp (nullable = true)\n",
      " |-- temperatureMax: double (nullable = true)\n",
      " |-- temperatureMin: double (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- Weekday/end: integer (nullable = true)\n",
      " |-- stdorToU: string (nullable = true)\n",
      " |-- Acorn_grouped: string (nullable = true)\n",
      " |-- weekDay_index: double (nullable = true)\n",
      " |-- precipType_index: double (nullable = true)\n",
      " |-- summary_index: double (nullable = true)\n",
      " |-- stdorToU_index: double (nullable = true)\n",
      " |-- Acorn_grouped_index: double (nullable = true)\n",
      " |-- category_weekDay_index: vector (nullable = true)\n",
      " |-- category_precipType_index: vector (nullable = true)\n",
      " |-- category_summary_index: vector (nullable = true)\n",
      " |-- category_stdorToU_index: vector (nullable = true)\n",
      " |-- category_Acorn_grouped_index: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_val = best_model.transform(test_df)\n",
    "pred_val.printSchema()\n",
    "evaluator = RegressionEvaluator(labelCol='label', predictionCol='prediction', metricName=\"rmse\")\n",
    "accuracy = evaluator.evaluate(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38920046777462886\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COmmon Method now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val.select(\"LCLid\",\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_df = get_aggregate(pred_val)\n",
    "aggregate_df = aggregate_df.withColumnRenamed(\"sum(label)\",\"label\")\n",
    "aggregate_df = aggregate_df.withColumnRenamed(\"sum(prediction)\",\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_df.select(\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_start_date = date(2013,11,1)\n",
    "train_end_date = date(2013,12,31)\n",
    "y_date = []\n",
    "Mape_date = []\n",
    "rmse_date = []\n",
    "while train_start_date <= train_end_date:\n",
    "    print(train_start_date)\n",
    "    y_actual,y_pred = select_predicted_actual(aggregate_df,train_start_date)\n",
    "    if len(y_actual) == 0:\n",
    "        train_start_date = train_start_date + timedelta(1)\n",
    "        continue\n",
    "    Mape_date.append(mean_absolute_percentage_error(y_actual,y_pred))\n",
    "    rmse_date.append(root_mean_squared_error(y_actual,y_pred))\n",
    "    y_date.append(train_start_date)\n",
    "    train_start_date = train_start_date + timedelta(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del y_date[2]\n",
    "# fig, (ax1,ax2) = plt.subplots(1,2, figsize =(8,6))\n",
    "# ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "# ax1.xaxis.set_major_locator(mdates.DayLocator())\n",
    "# ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "# ax2.xaxis.set_major_locator(mdates.DayLocator())\n",
    "# ax1.plot(y_date,Mape_date)\n",
    "# ax2.plot(y_date,rmse_date)\n",
    "# fig.autofmt_xdate()\n",
    "# ax1.set_xlabel('k')\n",
    "# ax1.set_ylabel('cost')\n",
    "date_time = pd.to_datetime(y_date)\n",
    "DF = pd.DataFrame()\n",
    "DF['Mape_date'] = Mape_date\n",
    "DF = DF.set_index(date_time)\n",
    "\n",
    "DF1 = pd.DataFrame()\n",
    "DF1['rmse_date'] = rmse_date\n",
    "DF1 = DF1.set_index(date_time)\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize =(8,6))\n",
    "fig.subplots_adjust(bottom=0.3)\n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=90)\n",
    "ax1.plot(DF)\n",
    "ax2.plot(DF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "print(\"Mean RMSE = {}, Mean Mape = {}\".format(mean(rmse_date),mean(Mape_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(base_path+\"rf_bin_128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
