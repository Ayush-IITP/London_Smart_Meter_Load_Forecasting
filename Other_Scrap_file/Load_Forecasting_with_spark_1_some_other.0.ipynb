{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "from time import time \n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "import math\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stdorToU</th>\n",
       "      <th>Acorn</th>\n",
       "      <th>Acorn_grouped</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LCLid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAC005492</th>\n",
       "      <td>ToU</td>\n",
       "      <td>ACORN-</td>\n",
       "      <td>ACORN-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAC001074</th>\n",
       "      <td>ToU</td>\n",
       "      <td>ACORN-</td>\n",
       "      <td>ACORN-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAC000002</th>\n",
       "      <td>Std</td>\n",
       "      <td>ACORN-A</td>\n",
       "      <td>Affluent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAC003613</th>\n",
       "      <td>Std</td>\n",
       "      <td>ACORN-A</td>\n",
       "      <td>Affluent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAC003597</th>\n",
       "      <td>Std</td>\n",
       "      <td>ACORN-A</td>\n",
       "      <td>Affluent</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          stdorToU    Acorn Acorn_grouped  file\n",
       "LCLid                                          \n",
       "MAC005492      ToU   ACORN-        ACORN-     0\n",
       "MAC001074      ToU   ACORN-        ACORN-     0\n",
       "MAC000002      Std  ACORN-A      Affluent     0\n",
       "MAC003613      Std  ACORN-A      Affluent     0\n",
       "MAC003597      Std  ACORN-A      Affluent     0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "# block = pd.read_csv('file:////mnt/sparklingwater/smart_wide/wide_combine.csv', parse_dates=['day'], index_col=[0,1])\n",
    "# We tried to import from mongodb (see screenshot on presentation) but it was too slow. Thus, we chose to read directly from disk for final model.\n",
    "base_path = \"/home/darkmatter/Desktop/smart-meters-in-london/\"\n",
    "household = pd.read_csv(base_path + \"informations_households.csv\", index_col=0)\n",
    "weather = pd.read_csv(base_path + \"weather_daily_darksky.csv\", parse_dates=['time'])\n",
    "\n",
    "# block.fillna(0, inplace=True)\n",
    "household['file'] = household.file.astype('category').cat.codes\n",
    "\n",
    "pred_date = date(2014,2,1)\n",
    "start_date = pred_date - timedelta(days=3)\n",
    "# df_part = block.loc[(block.index.get_level_values(1)>=pd.to_datetime(start_date))&                  (block.index.get_level_values(1)<pd.to_datetime(pred_date))]\n",
    "# df_part\n",
    "# weather.head()\n",
    "household.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, window_day_num, first_pred_date, n_range=1, day_skip=7, pred_num_period=4):\n",
    "    \n",
    "    user_index = df.index.get_level_values(0).unique()\n",
    "    \n",
    "    for n in range(n_range):\n",
    "        \n",
    "        pred_date = first_pred_date - timedelta(days=day_skip*n)\n",
    "        \n",
    "        # get day mean       \n",
    "        data_df = pd.DataFrame(index=user_index)\n",
    "        for i in range(1, window_day_num+1):\n",
    "            current_date = pred_date - timedelta(days=i)\n",
    "            subset = df.xs(current_date, level=1).mean(axis=1).reindex(user_index).values\n",
    "            data_df['day%dmean'%i] = subset\n",
    "        \n",
    "        # get hourly mean\n",
    "        start_date = pred_date - timedelta(days=window_day_num)\n",
    "        df_part = df.loc[(df.index.get_level_values(1)>=pd.to_datetime(start_date))&(df.index.get_level_values(1)<pd.to_datetime(pred_date))]\n",
    "        hourly_mean = df_part.groupby('LCLid').mean().reindex(user_index)\n",
    "        data_df = pd.concat([data_df, hourly_mean], axis=1)\n",
    "        \n",
    "        # get weather data\n",
    "        for i in range(1, window_day_num+1):\n",
    "            current_date = pred_date - timedelta(days=i+1)\n",
    "            w_data = weather.loc[weather.time==current_date]\n",
    "            if w_data.shape[0] == 0:\n",
    "                data_df['temp_max_%d'%i] = np.nan\n",
    "                data_df['temp_min_%d'%i] = np.nan\n",
    "            else:\n",
    "                data_df['temp_max_%d'%i] = w_data['temperatureMax'].iloc[0]\n",
    "                data_df['temp_min_%d'%i] = w_data['temperatureMin'].iloc[0]\n",
    "\n",
    "        # household data\n",
    "        data_df = data_df.join(household[['file']])\n",
    "        \n",
    "        # get label\n",
    "        pred_length = int(48 / pred_num_period)\n",
    "        for i in range(pred_num_period):\n",
    "            period_cols = ['hh_%d'%x for x in range(pred_length*i, pred_length*(i+1))]\n",
    "            pred_period_mean = df.xs(pred_date, level=1)[period_cols].mean(axis=1).reindex(user_index)\n",
    "            data_df['pred_period_%d'%i] = pred_period_mean.values\n",
    "        \n",
    "        if n == 0: data_df_combine = data_df\n",
    "        elif n > 0: data_df_combine = pd.concat([data_df_combine, data_df], axis=0)\n",
    "    \n",
    "    return data_df_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'block' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8e140d7b15ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_num_period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2014\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_num_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_num_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2014\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_num_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_num_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train_df.fillna(0, inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'block' is not defined"
     ]
    }
   ],
   "source": [
    "pred_num_period = 12\n",
    "train_df = prepare_dataset(block, 10, date(2014,2,1), n_range=20, pred_num_period=pred_num_period)\n",
    "val_df = prepare_dataset(block, 10, date(2014,2,8), pred_num_period=pred_num_period)\n",
    "\n",
    "# train_df.fillna(0, inplace=True)\n",
    "# val_df.fillna(0, inplace=True)\n",
    "train_df.dropna(inplace=True)\n",
    "val_df.dropna(inplace=True)\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName('smartcity')\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "train_spark_df = sqlContext.createDataFrame(train_df)\n",
    "val_spark_df = sqlContext.createDataFrame(val_df)\n",
    "\n",
    "pred_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_spark_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2448ad07d59d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_num_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mva\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_spark_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpred_num_period\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlabel_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pred_period_%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mva\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_spark_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mva\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_spark_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_spark_df' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(pred_num_period):\n",
    "    va = VectorAssembler(outputCol='features', inputCols=train_spark_df.columns[:-pred_num_period])\n",
    "    label_col = 'pred_period_%d'%i\n",
    "    train_va = va.transform(train_spark_df).select('features', label_col).withColumnRenamed(label_col, 'label').cache()\n",
    "    val_va = va.transform(val_spark_df).select('features', label_col).withColumnRenamed(label_col, 'label').cache()\n",
    "\n",
    "    train_va.count(); val_va.count();\n",
    "\n",
    "    rf = RandomForestRegressor(maxDepth=10, numTrees=10, maxBins=128)\n",
    "    rfmodel = rf.fit(train_va)\n",
    "\n",
    "    pred_val = rfmodel.transform(val_va)\n",
    "    pred_list.append(pred_val.select('prediction').rdd.map(lambda x: x[0]).collect())\n",
    "    evaluator = RegressionEvaluator(labelCol='label', predictionCol='prediction', metricName=\"rmse\")\n",
    "    accuracy = evaluator.evaluate(pred_val)\n",
    "    print('RMSE for period %d: %.4f'%(i+1, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c20b06ed275e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'time: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_list' is not defined"
     ]
    }
   ],
   "source": [
    "pred = np.stack(pred_list, axis=1)\n",
    "\n",
    "sc.stop()\n",
    "\n",
    "print ('time: ' + str(time()-start))\n",
    "\n",
    "# % matplotlib inline\n",
    "# from matplotlib import pyplot as plt\n",
    "# user_id += 1\n",
    "# plt.plot(np.repeat(pred[user_id, :], 2), color='red') # prediction\n",
    "# plt.plot(np.repeat(val_df.iloc[user_id, -12:], 2).values) # true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
