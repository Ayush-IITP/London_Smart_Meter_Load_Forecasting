{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from handyspark import *\n",
    "from pyspark.sql import functions as sf\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark.sql.functions import col, avg, date_format,month,hour,lag, date_sub,lit\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DateType\n",
    "import pandas as pd\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, OneHotEncoder\n",
    "from datetime import datetime, timedelta, date\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://172.16.27.115:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://172.16.27.115:7077 appName=spark>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.stop()\n",
    "sc = pyspark.SparkContext(master=\"spark://172.16.27.115:7077\",appName=\"spark\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/media/iitp/disk/smart-meters-in-london/\"\n",
    "sqlcontext = SQLContext(sc)\n",
    "household_info = sqlcontext.read.csv(base_path+\"informations_households.csv\",header=True,inferSchema=True)\n",
    "household_mini = sc.parallelize(household_info.take(2500)).toDF()\n",
    "# household_mini = household_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df):\n",
    "    # Resampling to 1 hour and extracting variable like month,hour,weekday etc.\n",
    "    df = df.select(\"LCLID\",\"tstp\",\"energy(kWh/hh)\",date_format(\"tstp\",\"yyyy-MM-dd\").alias(\"date\"),date_format(\"tstp\",'HH:mm').alias(\"start time\"),date_format(\"tstp\",'E').alias(\"weekDay\"),month(\"tstp\").alias(\"month\"),hour(\"tstp\").alias(\"hour\"))\n",
    "    df1 = (df.groupby('LCLID',\"date\",\"hour\").sum(\"energy(kWh/hh)\")).orderBy('date','hour',ascending=True)\n",
    "    df1 = df1.withColumnRenamed(\"sum(energy(kWh/hh))\",\"energy(kWh/h)\")\n",
    "    resampled_df = df1.select(\"LCLid\",\"date\",\"hour\",\"energy(kWh/h)\",month(\"date\").alias(\"month\"),date_format(\"date\",'E').alias(\"weekDay\"))\n",
    "    resampled_df = resampled_df.withColumn(\"energy(kWh/h)\", sf.round(resampled_df[\"energy(kWh/h)\"], 3))\n",
    "    resampled_df = resampled_df.withColumn(\"date\", resampled_df[\"date\"].cast(DateType()))\n",
    "#     resampled_df.printSchema()\n",
    "#     resampled_df.show()\n",
    "    \n",
    "#     # window period = 2 for lag input for same hour,same-1,same-2 \n",
    "    window = Window.partitionBy('LCLid').orderBy('date','hour')\n",
    "    for lag_hour in range(0,3):\n",
    "        for diff in range(1,3):\n",
    "            resampled_df = resampled_df.withColumn('{}_diff_energy_t_{}'.format(diff,lag_hour),lag(resampled_df['energy(kWh/h)'], count=24*diff+lag_hour).over(window)) \n",
    "#     df_resample_lag.show()\n",
    "    \n",
    "    # 4 weeks previous lag value of same time\n",
    "    for lag_week in range(1,5):\n",
    "        resampled_df = resampled_df.withColumn('diff_energy_week_t_{}'.format(lag_week),lag(resampled_df['energy(kWh/h)'], count=24*7*lag_week).over(window)) \n",
    "\n",
    "    df_resample_lag = resampled_df\n",
    "#     df_resample_lag.printSchema()    \n",
    "    # Mean of previous 2 days\n",
    "    df_resample_lag = df_resample_lag.withColumn(\"rnk\",sf.dense_rank().over(Window.partitionBy('LCLid').orderBy('date')))\n",
    "    for days in range(1,3):\n",
    "        df_resample_lag = df_resample_lag.withColumn(\"mean_{}\".format(days),avg(\"energy(kWh/h)\").over(Window.partitionBy(\"LCLid\").orderBy(\"rnk\").rangeBetween(-days,-days)))\n",
    "#     df_resample_lag.show()\n",
    "    # Min power of previous 2 days\n",
    "    for days in range(1,3):\n",
    "        df_resample_lag = df_resample_lag.withColumn(\"min_{}\".format(days),sf.min(\"energy(kWh/h)\").over(Window.partitionBy(\"LCLid\").orderBy(\"rnk\").rangeBetween(-days,-days)))\n",
    "        df_resample_lag = df_resample_lag.withColumn(\"max_{}\".format(days),sf.max(\"energy(kWh/h)\").over(Window.partitionBy(\"LCLid\").orderBy(\"rnk\").rangeBetween(-days,-days)))\n",
    "    \n",
    "    return df_resample_lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset_df holds lag variable and other metric variable, weather variable need to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_39\n",
      "block_43\n",
      "block_19\n",
      "block_35\n",
      "block_26\n",
      "block_20\n",
      "block_12\n",
      "block_21\n",
      "block_36\n",
      "block_49\n",
      "block_18\n",
      "block_44\n",
      "block_8\n",
      "block_4\n",
      "block_29\n",
      "block_38\n",
      "block_47\n",
      "block_48\n",
      "block_42\n",
      "block_27\n",
      "block_1\n",
      "block_3\n",
      "block_46\n",
      "block_32\n",
      "block_45\n",
      "block_40\n",
      "block_15\n",
      "block_5\n",
      "block_28\n",
      "block_24\n",
      "block_33\n",
      "block_23\n",
      "block_31\n",
      "block_0\n",
      "block_14\n",
      "block_41\n",
      "block_22\n",
      "block_30\n",
      "block_37\n",
      "block_10\n",
      "block_9\n",
      "block_11\n",
      "block_6\n",
      "block_2\n",
      "block_7\n",
      "block_25\n",
      "block_16\n",
      "block_13\n",
      "block_34\n",
      "block_17\n",
      "+---------+----------+----+-------------+-----+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+--------------------+--------------------+--------------------+--------------------+------+------+-----+-----+-----+-----+\n",
      "|    LCLid|      date|hour|energy(kWh/h)|month|weekDay|1_diff_energy_t_0|2_diff_energy_t_0|1_diff_energy_t_1|2_diff_energy_t_1|1_diff_energy_t_2|2_diff_energy_t_2|diff_energy_week_t_1|diff_energy_week_t_2|diff_energy_week_t_3|diff_energy_week_t_4|mean_1|mean_2|min_1|max_1|min_2|max_2|\n",
      "+---------+----------+----+-------------+-----+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+--------------------+--------------------+--------------------+--------------------+------+------+-----+-----+-----+-----+\n",
      "|MAC005306|2012-02-15|  12|        0.424|    2|    Wed|             null|             null|             null|             null|             null|             null|                null|                null|                null|                null|  null|  null| null| null| null| null|\n",
      "|MAC005306|2012-02-15|  13|        0.375|    2|    Wed|             null|             null|             null|             null|             null|             null|                null|                null|                null|                null|  null|  null| null| null| null| null|\n",
      "+---------+----------+----+-------------+-----+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+--------------------+--------------------+--------------------+--------------------+------+------+-----+-----+-----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "avg_house_data = []\n",
    "df_file = household_mini.select(\"file\").distinct()\n",
    "dataset_df = []\n",
    "for row in df_file.rdd.collect():\n",
    "    file = row.file\n",
    "    print(file)\n",
    "    file_path = base_path + \"halfhourly_dataset/\"+ file+\".csv\"\n",
    "    half_hourly_consumption_data = sqlcontext.read.csv(file_path,header=True,inferSchema=True)\n",
    "    half_hourly_consumption_data.dropna(how='any')\n",
    "    half_hourly_consumption_data = half_hourly_consumption_data.withColumn(\"energy(kWh/hh)\",\n",
    "                                                                           half_hourly_consumption_data[\"energy(kWh/hh)\"].cast(\"float\"))\n",
    "#     half_hourly_consumption_data.printSchema()\n",
    "    df = prepare_dataset(half_hourly_consumption_data)\n",
    "    df = df.drop(\"rnk\")\n",
    "    if flag == 0:\n",
    "        dataset_df = sqlcontext.createDataFrame([],df.schema)\n",
    "        flag = 1\n",
    "    dataset_df = dataset_df.union(df)\n",
    "dataset_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering data for year 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df.filter((dataset_df.date >= date(2013,1,1)) & (dataset_df.date <= date(2013,12,31)))\n",
    "#dataset_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For adding weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- windBearing: integer (nullable = true)\n",
      " |-- dewPoint: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- windSpeed: double (nullable = true)\n",
      " |-- precipType: string (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- hour1: integer (nullable = true)\n",
      " |-- date1: date (nullable = true)\n",
      " |-- date2: date (nullable = true)\n",
      " |-- temperatureMax: double (nullable = true)\n",
      " |-- temperatureMin: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_data = sqlcontext.read.csv(base_path+\"weather_hourly_darksky.csv\",header=True,inferSchema=True)\n",
    "weather_daily_data = sqlcontext.read.csv(base_path+\"weather_daily_darksky.csv\",header=True,inferSchema=True)\n",
    "weather_daily_data = weather_daily_data.select(date_format(\"temperatureMaxTime\",\"yyyy-MM-dd\").alias(\"date2\"),\"temperatureMax\",\"temperatureMin\")\n",
    "weather_daily_data = weather_daily_data.withColumn(\"date2\",weather_daily_data[\"date2\"].cast(DateType()))\n",
    "weather_data = weather_data.withColumn(\"hour1\",hour(weather_data[\"time\"]))\n",
    "weather_data = weather_data.withColumn(\"date1\",date_format(weather_data[\"time\"],\"yyyy-MM-dd\").cast(DateType()))\n",
    "weather_data = weather_data.drop(\"time\",\"icon\",\"temperature\")\n",
    "weather_data = weather_data.join(weather_daily_data,(weather_daily_data.date2 == weather_data.date1))\n",
    "weather_data.printSchema()\n",
    "# df_full_dataset = dataset_df.join(weather_data,(dataset_df.date == weather_data.date1) & (dataset_df.hour == weather_data.hour1))\n",
    "# df_full_dataset = df_full_dataset.drop(\"hour1\",\"date1\")\n",
    "# df_full_dataset.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding Holiday column treating weekend as holiday too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data = sqlcontext.read.csv(base_path+\"uk_bank_holidays.csv\",header=True,inferSchema=True)\n",
    "holiday_data = holiday_data.withColumn(\"Bank holidays\",date_format(holiday_data[\"Bank holidays\"],\"yyyy-MM-dd\").cast(DateType()))\n",
    "holiday_data = holiday_data.select(\"Bank holidays\")\n",
    "holiday_data = holiday_data.withColumn(\"holiday\",lit(1))\n",
    "# feature_df = df_full_dataset.join(holiday_data,holiday_data[\"Bank holidays\"] == df_full_dataset[\"date\"],how=\"left_outer\")\n",
    "# feature_df = feature_df.fillna({'holiday':'0'})\n",
    "# feature_df = feature_df.drop(\"Bank holidays\")\n",
    "# feature_df.select(\"holiday\").show(2)\n",
    "# feature_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## joining with main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LCLid: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- energy(kWh/h): double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- weekDay: string (nullable = true)\n",
      " |-- 1_diff_energy_t_0: double (nullable = true)\n",
      " |-- 2_diff_energy_t_0: double (nullable = true)\n",
      " |-- 1_diff_energy_t_1: double (nullable = true)\n",
      " |-- 2_diff_energy_t_1: double (nullable = true)\n",
      " |-- 1_diff_energy_t_2: double (nullable = true)\n",
      " |-- 2_diff_energy_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_1: double (nullable = true)\n",
      " |-- diff_energy_week_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_3: double (nullable = true)\n",
      " |-- diff_energy_week_t_4: double (nullable = true)\n",
      " |-- mean_1: double (nullable = true)\n",
      " |-- mean_2: double (nullable = true)\n",
      " |-- min_1: double (nullable = true)\n",
      " |-- max_1: double (nullable = true)\n",
      " |-- min_2: double (nullable = true)\n",
      " |-- max_2: double (nullable = true)\n",
      " |-- holiday: integer (nullable = false)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- windBearing: integer (nullable = true)\n",
      " |-- dewPoint: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- windSpeed: double (nullable = true)\n",
      " |-- precipType: string (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- temperatureMax: double (nullable = true)\n",
      " |-- temperatureMin: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_holiday_df = holiday_data.join(weather_data,holiday_data[\"Bank holidays\"] == weather_data[\"date1\"])\n",
    "weather_holiday_df =  weather_holiday_df.drop(\"Bank holidays\")\n",
    "feature_df = dataset_df.join(weather_holiday_df,(dataset_df.date == weather_data.date1) & (dataset_df.hour == weather_data.hour1))\n",
    "feature_df = feature_df.fillna({'holiday':'0'})\n",
    "feature_df = feature_df.drop(\"hour1\",\"date1\",\"date2\")\n",
    "feature_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding week days or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LCLid: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- energy(kWh/h): double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- weekDay: string (nullable = true)\n",
      " |-- 1_diff_energy_t_0: double (nullable = true)\n",
      " |-- 2_diff_energy_t_0: double (nullable = true)\n",
      " |-- 1_diff_energy_t_1: double (nullable = true)\n",
      " |-- 2_diff_energy_t_1: double (nullable = true)\n",
      " |-- 1_diff_energy_t_2: double (nullable = true)\n",
      " |-- 2_diff_energy_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_1: double (nullable = true)\n",
      " |-- diff_energy_week_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_3: double (nullable = true)\n",
      " |-- diff_energy_week_t_4: double (nullable = true)\n",
      " |-- mean_1: double (nullable = true)\n",
      " |-- mean_2: double (nullable = true)\n",
      " |-- min_1: double (nullable = true)\n",
      " |-- max_1: double (nullable = true)\n",
      " |-- min_2: double (nullable = true)\n",
      " |-- max_2: double (nullable = true)\n",
      " |-- holiday: integer (nullable = false)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- windBearing: integer (nullable = true)\n",
      " |-- dewPoint: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- windSpeed: double (nullable = true)\n",
      " |-- precipType: string (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- temperatureMax: double (nullable = true)\n",
      " |-- temperatureMin: double (nullable = true)\n",
      " |-- Weekday/end: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_df = feature_df.withColumn(\"Weekday/end\",sf.when((col(\"weekDay\")==str(\"Sat\")) | (col(\"weekDay\")==str(\"Sat\")),1).otherwise(0))\n",
    "feature_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding Acorn grouped and cleaning mising and error data as [Row(Acorn_grouped='Adversity'),\n",
    " Row(Acorn_grouped='ACORN-'),\n",
    " Row(Acorn_grouped='Affluent'),\n",
    " Row(Acorn_grouped='ACORN-U'),\n",
    " Row(Acorn_grouped='Comfortable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LCLid: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- energy(kWh/h): double (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- weekDay: string (nullable = true)\n",
      " |-- 1_diff_energy_t_0: double (nullable = true)\n",
      " |-- 2_diff_energy_t_0: double (nullable = true)\n",
      " |-- 1_diff_energy_t_1: double (nullable = true)\n",
      " |-- 2_diff_energy_t_1: double (nullable = true)\n",
      " |-- 1_diff_energy_t_2: double (nullable = true)\n",
      " |-- 2_diff_energy_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_1: double (nullable = true)\n",
      " |-- diff_energy_week_t_2: double (nullable = true)\n",
      " |-- diff_energy_week_t_3: double (nullable = true)\n",
      " |-- diff_energy_week_t_4: double (nullable = true)\n",
      " |-- mean_1: double (nullable = true)\n",
      " |-- mean_2: double (nullable = true)\n",
      " |-- min_1: double (nullable = true)\n",
      " |-- max_1: double (nullable = true)\n",
      " |-- min_2: double (nullable = true)\n",
      " |-- max_2: double (nullable = true)\n",
      " |-- holiday: integer (nullable = false)\n",
      " |-- visibility: double (nullable = true)\n",
      " |-- windBearing: integer (nullable = true)\n",
      " |-- dewPoint: double (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- apparentTemperature: double (nullable = true)\n",
      " |-- windSpeed: double (nullable = true)\n",
      " |-- precipType: string (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- temperatureMax: double (nullable = true)\n",
      " |-- temperatureMin: double (nullable = true)\n",
      " |-- Weekday/end: integer (nullable = false)\n",
      " |-- stdorToU: string (nullable = true)\n",
      " |-- Acorn_grouped: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(stdorToU='Std'), Row(stdorToU='ToU')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acorn_data_group = household_info.select(\"LCLid\",\"stdorToU\",\"Acorn_grouped\")\n",
    "Acorn_data_group.select(\"Acorn_grouped\").distinct().collect()\n",
    "possible_group = [\"Comfortable\",\"Affluent\",\"Adversity\"]\n",
    "Acorn_data_group = Acorn_data_group.filter(Acorn_data_group.Acorn_grouped.isin(possible_group))\n",
    "feature_df = feature_df.join(Acorn_data_group,[\"LCLid\"])                # preventing duplicate column in df\n",
    "feature_df.printSchema()\n",
    "Acorn_data_group.select(\"stdorToU\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>energy(kWh/h)</th>\n",
       "      <th>month</th>\n",
       "      <th>weekDay</th>\n",
       "      <th>1_diff_energy_t_0</th>\n",
       "      <th>2_diff_energy_t_0</th>\n",
       "      <th>1_diff_energy_t_1</th>\n",
       "      <th>2_diff_energy_t_1</th>\n",
       "      <th>1_diff_energy_t_2</th>\n",
       "      <th>2_diff_energy_t_2</th>\n",
       "      <th>diff_energy_week_t_1</th>\n",
       "      <th>diff_energy_week_t_2</th>\n",
       "      <th>diff_energy_week_t_3</th>\n",
       "      <th>diff_energy_week_t_4</th>\n",
       "      <th>mean_1</th>\n",
       "      <th>mean_2</th>\n",
       "      <th>min_1</th>\n",
       "      <th>max_1</th>\n",
       "      <th>min_2</th>\n",
       "      <th>max_2</th>\n",
       "      <th>holiday</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>pressure</th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>precipType</th>\n",
       "      <th>humidity</th>\n",
       "      <th>summary</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>Weekday/end</th>\n",
       "      <th>stdorToU</th>\n",
       "      <th>Acorn_grouped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC005306</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.186</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.101</td>\n",
       "      <td>1.852</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.197417</td>\n",
       "      <td>0.226625</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.097</td>\n",
       "      <td>1.361</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>ToU</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC005204</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.118</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.098417</td>\n",
       "      <td>0.131167</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>ToU</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC001725</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.431</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.669417</td>\n",
       "      <td>0.425375</td>\n",
       "      <td>0.343</td>\n",
       "      <td>2.591</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.771</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC001895</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.594</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.329</td>\n",
       "      <td>1.645</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.085</td>\n",
       "      <td>1.032</td>\n",
       "      <td>1.584</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.711708</td>\n",
       "      <td>1.006292</td>\n",
       "      <td>0.222</td>\n",
       "      <td>4.916</td>\n",
       "      <td>0.323</td>\n",
       "      <td>4.874</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC001699</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.233</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.259750</td>\n",
       "      <td>0.294167</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.721</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAC000443</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>2.708</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>1.356</td>\n",
       "      <td>1.117</td>\n",
       "      <td>1.179</td>\n",
       "      <td>1.253</td>\n",
       "      <td>1.219</td>\n",
       "      <td>1.356</td>\n",
       "      <td>2.079</td>\n",
       "      <td>2.580</td>\n",
       "      <td>3.018</td>\n",
       "      <td>2.043</td>\n",
       "      <td>1.535458</td>\n",
       "      <td>1.488500</td>\n",
       "      <td>0.213</td>\n",
       "      <td>3.681</td>\n",
       "      <td>0.308</td>\n",
       "      <td>3.195</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MAC001651</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.463</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.120</td>\n",
       "      <td>1.674</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.429708</td>\n",
       "      <td>0.218375</td>\n",
       "      <td>0.182</td>\n",
       "      <td>1.674</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>ToU</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MAC001720</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.682</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.287833</td>\n",
       "      <td>0.256417</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.551</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MAC005291</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.300</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.251458</td>\n",
       "      <td>0.124292</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.336</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>ToU</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MAC005284</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.226</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.113708</td>\n",
       "      <td>0.124083</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.293</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>ToU</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid        date  hour  energy(kWh/h)  month weekDay  \\\n",
       "0  MAC005306  2013-06-05    17          0.186      6     Wed   \n",
       "1  MAC005204  2013-06-05    17          0.118      6     Wed   \n",
       "2  MAC001725  2013-06-05    17          0.431      6     Wed   \n",
       "3  MAC001895  2013-06-05    17          0.594      6     Wed   \n",
       "4  MAC001699  2013-06-05    17          0.233      6     Wed   \n",
       "5  MAC000443  2013-06-05    17          2.708      6     Wed   \n",
       "6  MAC001651  2013-06-05    17          0.463      6     Wed   \n",
       "7  MAC001720  2013-06-05    17          0.682      6     Wed   \n",
       "8  MAC005291  2013-06-05    17          0.300      6     Wed   \n",
       "9  MAC005284  2013-06-05    17          0.226      6     Wed   \n",
       "\n",
       "   1_diff_energy_t_0  2_diff_energy_t_0  1_diff_energy_t_1  2_diff_energy_t_1  \\\n",
       "0              0.161              0.201              0.276              0.361   \n",
       "1              0.066              0.077              0.064              0.089   \n",
       "2              0.505              0.397              0.371              0.381   \n",
       "3              0.452              0.716              0.329              1.645   \n",
       "4              0.316              0.248              0.321              0.227   \n",
       "5              1.356              1.117              1.179              1.253   \n",
       "6              0.276              0.120              1.674              0.121   \n",
       "7              0.357              0.422              0.338              0.551   \n",
       "8              0.183              0.076              0.631              0.089   \n",
       "9              0.079              0.113              0.155              0.115   \n",
       "\n",
       "   1_diff_energy_t_2  2_diff_energy_t_2  diff_energy_week_t_1  \\\n",
       "0              0.224              0.101                 1.852   \n",
       "1              0.086              0.118                 0.343   \n",
       "2              0.343              0.771                 0.223   \n",
       "3              0.223              0.990                 1.085   \n",
       "4              0.316              0.227                 0.244   \n",
       "5              1.219              1.356                 2.079   \n",
       "6              0.440              0.121                 0.609   \n",
       "7              0.518              0.179                 0.609   \n",
       "8              0.870              0.072                 0.156   \n",
       "9              0.115              0.127                 0.071   \n",
       "\n",
       "   diff_energy_week_t_2  diff_energy_week_t_3  diff_energy_week_t_4    mean_1  \\\n",
       "0                 0.325                 0.272                 0.421  0.197417   \n",
       "1                 0.519                 0.129                 0.081  0.098417   \n",
       "2                 0.188                 0.498                 0.255  0.669417   \n",
       "3                 1.032                 1.584                 0.512  0.711708   \n",
       "4                 0.239                 0.243                 0.186  0.259750   \n",
       "5                 2.580                 3.018                 2.043  1.535458   \n",
       "6                 0.233                 0.633                 0.288  0.429708   \n",
       "7                 0.457                 0.902                 0.456  0.287833   \n",
       "8                 0.085                 0.111                 0.051  0.251458   \n",
       "9                 0.155                 0.159                 0.147  0.113708   \n",
       "\n",
       "     mean_2  min_1  max_1  min_2  max_2  holiday  visibility  windBearing  \\\n",
       "0  0.226625  0.103  0.803  0.097  1.361        1        13.9           75   \n",
       "1  0.131167  0.049  0.326  0.055  0.578        1        13.9           75   \n",
       "2  0.425375  0.343  2.591  0.153  0.771        1        13.9           75   \n",
       "3  1.006292  0.222  4.916  0.323  4.874        1        13.9           75   \n",
       "4  0.294167  0.221  0.321  0.227  0.721        1        13.9           75   \n",
       "5  1.488500  0.213  3.681  0.308  3.195        1        13.9           75   \n",
       "6  0.218375  0.182  1.674  0.116  0.381        1        13.9           75   \n",
       "7  0.256417  0.109  0.680  0.113  0.551        1        13.9           75   \n",
       "8  0.124292  0.061  0.870  0.062  0.336        1        13.9           75   \n",
       "9  0.124083  0.042  0.312  0.042  0.293        1        13.9           75   \n",
       "\n",
       "   dewPoint  pressure  apparentTemperature  windSpeed precipType  humidity  \\\n",
       "0     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "1     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "2     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "3     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "4     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "5     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "6     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "7     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "8     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "9     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "\n",
       "         summary  temperatureMax  temperatureMin  Weekday/end stdorToU  \\\n",
       "0  Partly Cloudy           19.64            8.96            0      ToU   \n",
       "1  Partly Cloudy           19.64            8.96            0      ToU   \n",
       "2  Partly Cloudy           19.64            8.96            0      Std   \n",
       "3  Partly Cloudy           19.64            8.96            0      Std   \n",
       "4  Partly Cloudy           19.64            8.96            0      Std   \n",
       "5  Partly Cloudy           19.64            8.96            0      Std   \n",
       "6  Partly Cloudy           19.64            8.96            0      ToU   \n",
       "7  Partly Cloudy           19.64            8.96            0      Std   \n",
       "8  Partly Cloudy           19.64            8.96            0      ToU   \n",
       "9  Partly Cloudy           19.64            8.96            0      ToU   \n",
       "\n",
       "  Acorn_grouped  \n",
       "0      Affluent  \n",
       "1      Affluent  \n",
       "2      Affluent  \n",
       "3      Affluent  \n",
       "4      Affluent  \n",
       "5      Affluent  \n",
       "6      Affluent  \n",
       "7      Affluent  \n",
       "8      Affluent  \n",
       "9      Affluent  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "feature_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking year 2013 in consideration   \n",
    "\n",
    "All points : 411720\n",
    "na points dropped : 411128  (without Acorn group join)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All points : 456722\n",
      "na points dropped : 454185\n"
     ]
    }
   ],
   "source": [
    "print(\"All points : {}\".format(feature_df.count()))\n",
    "feature_df = feature_df.na.drop()\n",
    "print(\"na points dropped : {}\".format(feature_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO : Instead of processing each LCLID process each file using window.partitionby(\"LCLID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# block_read = set([])\n",
    "# for row in household_mini.rdd.collect():\n",
    "#     house_id = row.LCLid\n",
    "#     file = row.file\n",
    "#     print(house_id,file)\n",
    "#     file_path = base_path + \"halfhourly_dataset/\"+ file+\".csv\"\n",
    "#     if file not in block_read:\n",
    "#         block_read.add(file)\n",
    "#         half_hourly_consumption_data = sqlContext.read.csv(file_path,header=True,inferSchema=True)\n",
    "#         half_hourly_consumption_data.dropna(how='any')\n",
    "#     indiv_house_data = half_hourly_consumption_data.where(col(\"LCLid\") == house_id)\n",
    "#     indiv_house_data = indiv_house_data.withColumnRenamed(\"energy(kWh/hh)\",\"energy\")\n",
    "#     indiv_house_data.show()\n",
    "#     indiv_house_data = indiv_house_data.withColumn(\"energy(kWh/hh)\", indiv_house_data[\"energy\"].cast(\"float\"))\n",
    "#     indiv_house_data = indiv_house_data.drop(\"energy\")\n",
    "#     indiv_house_data.printSchema()\n",
    "#     if indiv_house_data.rdd.isEmpty():\n",
    "#         print(\"Missing Id = {} in file = {}\".format(house_id,file))\n",
    "#         continue\n",
    "#     df = prepare_dataset(indiv_house_data)\n",
    "#     df.printSchema()\n",
    "#     df = df.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LCLid</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>energy(kWh/h)</th>\n",
       "      <th>month</th>\n",
       "      <th>weekDay</th>\n",
       "      <th>1_diff_energy_t_0</th>\n",
       "      <th>2_diff_energy_t_0</th>\n",
       "      <th>1_diff_energy_t_1</th>\n",
       "      <th>2_diff_energy_t_1</th>\n",
       "      <th>1_diff_energy_t_2</th>\n",
       "      <th>2_diff_energy_t_2</th>\n",
       "      <th>diff_energy_week_t_1</th>\n",
       "      <th>diff_energy_week_t_2</th>\n",
       "      <th>diff_energy_week_t_3</th>\n",
       "      <th>diff_energy_week_t_4</th>\n",
       "      <th>mean_1</th>\n",
       "      <th>mean_2</th>\n",
       "      <th>min_1</th>\n",
       "      <th>max_1</th>\n",
       "      <th>min_2</th>\n",
       "      <th>max_2</th>\n",
       "      <th>holiday</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>pressure</th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>precipType</th>\n",
       "      <th>humidity</th>\n",
       "      <th>summary</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>temperatureMin</th>\n",
       "      <th>Weekday/end</th>\n",
       "      <th>stdorToU</th>\n",
       "      <th>Acorn_grouped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAC003668</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>1.438</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>2.002</td>\n",
       "      <td>0.507</td>\n",
       "      <td>2.882</td>\n",
       "      <td>0.502</td>\n",
       "      <td>1.346</td>\n",
       "      <td>0.481</td>\n",
       "      <td>1.135</td>\n",
       "      <td>2.591</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.570</td>\n",
       "      <td>1.534833</td>\n",
       "      <td>1.410958</td>\n",
       "      <td>0.421</td>\n",
       "      <td>3.748</td>\n",
       "      <td>0.406</td>\n",
       "      <td>4.064</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAC003252</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.339</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.893</td>\n",
       "      <td>1.164</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.638</td>\n",
       "      <td>1.213</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.507958</td>\n",
       "      <td>0.540708</td>\n",
       "      <td>0.159</td>\n",
       "      <td>1.295</td>\n",
       "      <td>0.128</td>\n",
       "      <td>2.778</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAC003775</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.526</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.405</td>\n",
       "      <td>2.198</td>\n",
       "      <td>1.867</td>\n",
       "      <td>1.187</td>\n",
       "      <td>1.104</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.258</td>\n",
       "      <td>1.278</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.934542</td>\n",
       "      <td>0.997458</td>\n",
       "      <td>0.192</td>\n",
       "      <td>2.198</td>\n",
       "      <td>0.223</td>\n",
       "      <td>4.209</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAC003400</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.320</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.412750</td>\n",
       "      <td>0.406375</td>\n",
       "      <td>0.106</td>\n",
       "      <td>1.223</td>\n",
       "      <td>0.107</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAC003613</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.687</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.917</td>\n",
       "      <td>1.185</td>\n",
       "      <td>0.881</td>\n",
       "      <td>1.126</td>\n",
       "      <td>2.842</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.813250</td>\n",
       "      <td>1.111958</td>\n",
       "      <td>0.349</td>\n",
       "      <td>2.306</td>\n",
       "      <td>0.377</td>\n",
       "      <td>2.434</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAC003718</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.342583</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.158</td>\n",
       "      <td>1.471</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MAC003597</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>1.786</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>2.436</td>\n",
       "      <td>1.205</td>\n",
       "      <td>2.073</td>\n",
       "      <td>1.373</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.821</td>\n",
       "      <td>1.340</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.822</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.808458</td>\n",
       "      <td>0.466</td>\n",
       "      <td>2.436</td>\n",
       "      <td>0.468</td>\n",
       "      <td>1.722</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MAC003463</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.361</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.598</td>\n",
       "      <td>1.804</td>\n",
       "      <td>1.378</td>\n",
       "      <td>0.393</td>\n",
       "      <td>1.712</td>\n",
       "      <td>0.504542</td>\n",
       "      <td>0.389792</td>\n",
       "      <td>0.201</td>\n",
       "      <td>1.368</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.937</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MAC003656</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.731</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.296</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.779042</td>\n",
       "      <td>0.304</td>\n",
       "      <td>2.877</td>\n",
       "      <td>0.308</td>\n",
       "      <td>1.924</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MAC003557</td>\n",
       "      <td>2013-06-05</td>\n",
       "      <td>17</td>\n",
       "      <td>0.374</td>\n",
       "      <td>6</td>\n",
       "      <td>Wed</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.313917</td>\n",
       "      <td>0.254708</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1.232</td>\n",
       "      <td>0.102</td>\n",
       "      <td>1.194</td>\n",
       "      <td>1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>75</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1019.55</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.18</td>\n",
       "      <td>rain</td>\n",
       "      <td>0.58</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>19.64</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Std</td>\n",
       "      <td>Affluent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LCLid        date  hour  energy(kWh/h)  month weekDay  \\\n",
       "0  MAC003668  2013-06-05    17          1.438      6     Wed   \n",
       "1  MAC003252  2013-06-05    17          0.339      6     Wed   \n",
       "2  MAC003775  2013-06-05    17          0.526      6     Wed   \n",
       "3  MAC003400  2013-06-05    17          0.320      6     Wed   \n",
       "4  MAC003613  2013-06-05    17          0.687      6     Wed   \n",
       "5  MAC003718  2013-06-05    17          0.413      6     Wed   \n",
       "6  MAC003597  2013-06-05    17          1.786      6     Wed   \n",
       "7  MAC003463  2013-06-05    17          0.361      6     Wed   \n",
       "8  MAC003656  2013-06-05    17          0.731      6     Wed   \n",
       "9  MAC003557  2013-06-05    17          0.374      6     Wed   \n",
       "\n",
       "   1_diff_energy_t_0  2_diff_energy_t_0  1_diff_energy_t_1  2_diff_energy_t_1  \\\n",
       "0              2.002              0.507              2.882              0.502   \n",
       "1              0.893              1.164              0.686              0.638   \n",
       "2              0.664              0.405              2.198              1.867   \n",
       "3              0.407              0.189              0.407              0.193   \n",
       "4              0.838              0.890              0.917              1.185   \n",
       "5              0.188              0.194              0.179              0.158   \n",
       "6              2.436              1.205              2.073              1.373   \n",
       "7              0.729              0.710              0.586              0.937   \n",
       "8              0.887              0.701              0.551              0.563   \n",
       "9              0.348              0.275              0.216              0.194   \n",
       "\n",
       "   1_diff_energy_t_2  2_diff_energy_t_2  diff_energy_week_t_1  \\\n",
       "0              1.346              0.481                 1.135   \n",
       "1              1.213              0.216                 0.787   \n",
       "2              1.187              1.104                 0.384   \n",
       "3              0.374              0.279                 0.504   \n",
       "4              0.881              1.126                 2.842   \n",
       "5              0.233              0.325                 0.628   \n",
       "6              0.912              0.821                 1.340   \n",
       "7              0.493              0.598                 1.804   \n",
       "8              0.585              1.296                 0.330   \n",
       "9              0.150              0.144                 0.099   \n",
       "\n",
       "   diff_energy_week_t_2  diff_energy_week_t_3  diff_energy_week_t_4    mean_1  \\\n",
       "0                 2.591                 0.477                 0.570  1.534833   \n",
       "1                 0.732                 0.304                 0.678  0.507958   \n",
       "2                 0.258                 1.278                 0.486  0.934542   \n",
       "3                 0.454                 0.464                 0.278  0.412750   \n",
       "4                 0.772                 0.718                 0.859  0.813250   \n",
       "5                 0.190                 0.271                 0.323  0.342583   \n",
       "6                 0.693                 0.822                 1.193  0.979000   \n",
       "7                 1.378                 0.393                 1.712  0.504542   \n",
       "8                 0.382                 0.390                 0.342  0.645000   \n",
       "9                 0.397                 0.315                 0.219  0.313917   \n",
       "\n",
       "     mean_2  min_1  max_1  min_2  max_2  holiday  visibility  windBearing  \\\n",
       "0  1.410958  0.421  3.748  0.406  4.064        1        13.9           75   \n",
       "1  0.540708  0.159  1.295  0.128  2.778        1        13.9           75   \n",
       "2  0.997458  0.192  2.198  0.223  4.209        1        13.9           75   \n",
       "3  0.406375  0.106  1.223  0.107  1.053        1        13.9           75   \n",
       "4  1.111958  0.349  2.306  0.377  2.434        1        13.9           75   \n",
       "5  0.433500  0.172  0.877  0.158  1.471        1        13.9           75   \n",
       "6  0.808458  0.466  2.436  0.468  1.722        1        13.9           75   \n",
       "7  0.389792  0.201  1.368  0.171  0.937        1        13.9           75   \n",
       "8  0.779042  0.304  2.877  0.308  1.924        1        13.9           75   \n",
       "9  0.254708  0.105  1.232  0.102  1.194        1        13.9           75   \n",
       "\n",
       "   dewPoint  pressure  apparentTemperature  windSpeed precipType  humidity  \\\n",
       "0     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "1     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "2     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "3     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "4     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "5     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "6     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "7     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "8     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "9     10.51   1019.55                18.98       4.18       rain      0.58   \n",
       "\n",
       "         summary  temperatureMax  temperatureMin  Weekday/end stdorToU  \\\n",
       "0  Partly Cloudy           19.64            8.96            0      Std   \n",
       "1  Partly Cloudy           19.64            8.96            0      Std   \n",
       "2  Partly Cloudy           19.64            8.96            0      Std   \n",
       "3  Partly Cloudy           19.64            8.96            0      Std   \n",
       "4  Partly Cloudy           19.64            8.96            0      Std   \n",
       "5  Partly Cloudy           19.64            8.96            0      Std   \n",
       "6  Partly Cloudy           19.64            8.96            0      Std   \n",
       "7  Partly Cloudy           19.64            8.96            0      Std   \n",
       "8  Partly Cloudy           19.64            8.96            0      Std   \n",
       "9  Partly Cloudy           19.64            8.96            0      Std   \n",
       "\n",
       "  Acorn_grouped  \n",
       "0      Affluent  \n",
       "1      Affluent  \n",
       "2      Affluent  \n",
       "3      Affluent  \n",
       "4      Affluent  \n",
       "5      Affluent  \n",
       "6      Affluent  \n",
       "7      Affluent  \n",
       "8      Affluent  \n",
       "9      Affluent  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "feature_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(stdorToU='Std')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.select(\"stdorToU\").distinct().collect()\n",
    "# feature_df1.where(col(\"LCLid\") == )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCols = [\"weekDay\",\"precipType\",\"summary\",\"stdorToU\",\"Acorn_grouped\"]\n",
    "outputCols = [\"weekDay_index\",\"precipType_index\",\"summary_index\",\"stdorToU_index\",\"Acorn_grouped_index\"]\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(feature_df) for column in inputCols ]\n",
    "# # stringIndexer = StringIndexer(inputCol=inputCols, outputCol=outputCols)\n",
    "# encoder = OneHotEncoderEstimator(inputCols=outputCols, outputCols=outputCols)\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df = pipeline.fit(feature_df).transform(feature_df)\n",
    "\n",
    "# encoder = OneHotEncoder(inputCols=outputCols, outputCols=outputCols)\n",
    "# pipeline = Pipeline(stages=encoder)\n",
    "# pipeline.fit(df).transform(df).show()\n",
    "# # model = stringIndexer.fit(df)\n",
    "# # indexed = model.transform(df)\n",
    "# outputCols.remove(\"Acorn_grouped_index\")\n",
    "# for col in outputCols: \n",
    "#     encoder = OneHotEncoder(inputCol=col, outputCol=\"category_{}\".format(col))\n",
    "#     df_encoded = encoder.transform(df).cache()\n",
    "# df_encoded.show()\n",
    "# # columns = df_encoded.columns\n",
    "# # inputcols = columns[4:]\n",
    "# # inputcols.append(columns[2])\n",
    "# # inputcols.remove(\"Index_Week\")\n",
    "# # inputcols.remove(\"weekDay\")\n",
    "\n",
    "# # vecAssembler = VectorAssembler(inputCols=inputcols, outputCol=\"features\")\n",
    "# # df_feature = vecAssembler.transform(df_encoded)\n",
    "# # df_feature.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----+-------------+-----+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-----+-----+-----+-----+-------+----------+-----------+--------+--------+-------------------+---------+----------+--------+-------------+--------------+--------------+-----------+--------+-------------+-------------+----------------+-------------+--------------+-------------------+----------------------------+\n",
      "|    LCLid|      date|hour|energy(kWh/h)|month|weekDay|1_diff_energy_t_0|2_diff_energy_t_0|1_diff_energy_t_1|2_diff_energy_t_1|1_diff_energy_t_2|2_diff_energy_t_2|diff_energy_week_t_1|diff_energy_week_t_2|diff_energy_week_t_3|diff_energy_week_t_4|             mean_1|             mean_2|min_1|max_1|min_2|max_2|holiday|visibility|windBearing|dewPoint|pressure|apparentTemperature|windSpeed|precipType|humidity|      summary|temperatureMax|temperatureMin|Weekday/end|stdorToU|Acorn_grouped|weekDay_index|precipType_index|summary_index|stdorToU_index|Acorn_grouped_index|category_Acorn_grouped_index|\n",
      "+---------+----------+----+-------------+-----+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-----+-----+-----+-----+-------+----------+-----------+--------+--------+-------------------+---------+----------+--------+-------------+--------------+--------------+-----------+--------+-------------+-------------+----------------+-------------+--------------+-------------------+----------------------------+\n",
      "|MAC000443|2013-06-05|  17|        2.708|    6|    Wed|            1.356|            1.117|            1.179|            1.253|            1.219|            1.356|               2.079|                2.58|               3.018|               2.043| 1.5354583333333334| 1.4885000000000002|0.213|3.681|0.308|3.195|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     Std|     Affluent|          1.0|             0.0|          2.0|           0.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC001651|2013-06-05|  17|        0.463|    6|    Wed|            0.276|             0.12|            1.674|            0.121|             0.44|            0.121|               0.609|               0.233|               0.633|               0.288| 0.4297083333333333|0.21837500000000007|0.182|1.674|0.116|0.381|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC001720|2013-06-05|  17|        0.682|    6|    Wed|            0.357|            0.422|            0.338|            0.551|            0.518|            0.179|               0.609|               0.457|               0.902|               0.456|0.28783333333333333| 0.2564166666666667|0.109| 0.68|0.113|0.551|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     Std|     Affluent|          1.0|             0.0|          2.0|           0.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC005291|2013-06-05|  17|          0.3|    6|    Wed|            0.183|            0.076|            0.631|            0.089|             0.87|            0.072|               0.156|               0.085|               0.111|               0.051| 0.2514583333333333|0.12429166666666665|0.061| 0.87|0.062|0.336|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC005284|2013-06-05|  17|        0.226|    6|    Wed|            0.079|            0.113|            0.155|            0.115|            0.115|            0.127|               0.071|               0.155|               0.159|               0.147|0.11370833333333334|0.12408333333333334|0.042|0.312|0.042|0.293|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC000538|2013-06-05|  17|        0.135|    6|    Wed|            0.104|            0.251|            0.242|              0.2|             0.11|            0.112|               0.559|               0.146|               0.117|               0.204| 0.1709166666666667|0.17054166666666667|0.085|0.371|0.077|0.528|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     Std|     Affluent|          1.0|             0.0|          2.0|           0.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC005180|2013-06-05|  17|        0.068|    6|    Wed|            0.059|            0.058|            0.066|            0.068|            0.054|            0.061|               0.058|               0.068|               0.066|               0.057|0.06337500000000001|0.06320833333333335|0.054|0.069|0.056|0.069|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC001274|2013-06-05|  17|        0.273|    6|    Wed|            0.449|            0.337|            0.444|            0.449|            0.388|            0.423|               0.373|               0.401|               0.388|               0.256| 0.2982083333333333|0.28200000000000003|0.147|0.449|0.153|0.449|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC001902|2013-06-05|  17|         0.44|    6|    Wed|            0.334|            0.266|            0.292|            0.372|            0.591|            0.268|               0.462|                 0.2|               0.483|               0.292|  1.352916666666667| 0.5672083333333334|0.174|2.477|0.219|1.513|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     Std|     Affluent|          1.0|             0.0|          2.0|           0.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC005290|2013-06-05|  17|        0.538|    6|    Wed|            1.441|            1.403|            0.713|            1.291|            0.755|            0.864|               0.771|               1.078|               0.781|               0.871| 0.9880833333333334| 0.9549583333333334|0.155| 5.21|0.162|4.116|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC005212|2013-06-05|  17|        0.141|    6|    Wed|            0.141|            0.132|            0.122|            0.112|            0.114|            0.102|               0.127|               0.126|               0.115|               0.144|0.19795833333333332|0.15845833333333334|0.105|0.532|0.099|0.374|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC001754|2013-06-05|  17|        0.063|    6|    Wed|            0.132|            0.064|             0.12|            0.047|            0.126|             0.06|               0.446|               0.066|               0.048|               0.069|0.21562499999999998|0.15633333333333335|0.048| 1.91|0.046|0.959|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     Std|     Affluent|          1.0|             0.0|          2.0|           0.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC001905|2013-06-05|  17|        0.038|    6|    Wed|            0.112|             0.05|            0.038|            0.101|             0.12|            0.037|               0.044|               0.056|               0.133|               0.039|0.13754166666666665|0.13287500000000002|0.038| 0.35|0.037|0.314|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     Std|     Affluent|          1.0|             0.0|          2.0|           0.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC005292|2013-06-05|  17|        0.104|    6|    Wed|            0.141|            0.221|             0.14|            0.619|             0.12|            0.696|               0.673|               0.208|                0.72|               0.108|0.22154166666666666| 0.2831249999999999|0.057| 0.93|0.061| 0.98|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC000562|2013-06-05|  17|         0.49|    6|    Wed|             0.34|            0.433|            0.301|            0.291|            0.125|             0.41|                0.24|                0.17|               0.079|               0.137|0.19337499999999996|0.22987500000000002| 0.08|0.731|  0.0|1.038|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     Std|     Affluent|          1.0|             0.0|          2.0|           0.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC001299|2013-06-05|  17|        0.331|    6|    Wed|            0.448|            0.596|            0.603|            0.327|            0.524|            0.506|               0.219|                0.16|               0.289|               0.198| 0.6752083333333334| 1.0824999999999998|0.257|2.683| 0.25|3.214|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC000438|2013-06-05|  17|        0.044|    6|    Wed|            0.126|            0.139|            0.034|            0.051|             0.12|            0.097|               0.065|                0.03|               0.057|                0.15|            0.09175|0.09229166666666667|0.034|0.152|0.039|0.139|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     Std|     Affluent|          1.0|             0.0|          2.0|           0.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC005250|2013-06-05|  17|        0.089|    6|    Wed|            0.135|             0.09|            0.075|            0.079|            0.101|            0.123|               0.132|               0.067|               0.308|               0.086| 0.3005416666666667|0.28387500000000004|0.067| 2.15|0.068|2.513|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC005279|2013-06-05|  17|        0.142|    6|    Wed|            0.161|            0.176|            0.148|            0.144|            0.138|            0.129|               0.132|               0.129|               0.117|                0.13| 0.1508333333333333|0.15208333333333332|0.126|0.194|0.129|0.189|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     ToU|     Affluent|          1.0|             0.0|          2.0|           1.0|                0.0|               (1,[0],[1.0])|\n",
      "|MAC000526|2013-06-05|  17|        0.407|    6|    Wed|            0.467|            0.551|            0.477|            0.429|            0.406|            0.523|               0.646|               0.459|               0.527|               0.525| 0.5092083333333334|0.45979166666666665|0.291|0.988|0.342|0.584|      1|      13.9|         75|   10.51| 1019.55|              18.98|     4.18|      rain|    0.58|Partly Cloudy|         19.64|          8.96|          0|     Std|     Affluent|          1.0|             0.0|          2.0|           0.0|                0.0|               (1,[0],[1.0])|\n",
      "+---------+----------+----+-------------+-----+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+--------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-----+-----+-----+-----+-------+----------+-----------+--------+--------+-------------------+---------+----------+--------+-------------+--------------+--------------+-----------+--------+-------------+-------------+----------------+-------------+--------------+-------------------+----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#outputCols.remove(\"Acorn_grouped_index\")\n",
    "for col in outputCols: \n",
    "    encoder = OneHotEncoder(inputCol=col, outputCol=\"category_{}\".format(col))\n",
    "    df_encoded = encoder.transform(df).cache()\n",
    "df_encoded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For declaring feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/iitp/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-320f361b8721>\", line 7, in <module>\n",
      "    inputcols1.remove(\"date2\")\n",
      "ValueError: list.remove(x): x not in list\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iitp/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iitp/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/iitp/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/iitp/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1452, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1409, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 671, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 717, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "columns = df_encoded.columns\n",
    "inputcols1 = columns[4:]\n",
    "inputcols1.append(columns[2])\n",
    "inputcols1 = set(inputcols1) - set(inputCols)\n",
    "inputcols1 = inputcols1 - set(outputCols)\n",
    "inputcols1 = list(inputcols1)\n",
    "inputcols1.remove(\"date2\")\n",
    "vecAssembler = VectorAssembler(inputCols=inputcols1, outputCol=\"features\")\n",
    "df_feature = vecAssembler.transform(df_encoded)\n",
    "df_feature.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "# row1 = df_feature.agg({\"date\": \"max\"}).collect()[0]\n",
    "print(type(row1[0]))\n",
    "df_feature.count()\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_feature.withColumnRenamed(\"energy(kWh/h)\",\"label\")\n",
    "# ****************** for 80-20 for each user *******************\n",
    "# train_df = df_feature.where(col(\"date\") <= ((df_feature.agg({\"date\": \"max\"}).collect()[0])[0]-timedelta(df.count()//(24*60))))\n",
    "# test_df = df_feature.where(col(\"date\") > ((df_feature.agg({\"date\": \"max\"}).collect()[0])[0]-timedelta(df.count()//(24*60))))\n",
    "# ***************8 month train 4 month test\n",
    "train_df = df_feature.where(df_feature[\"date\"] <= date(2013,8,31))\n",
    "test_df = df_feature.where(df_feature[\"date\"] > date(2013,8,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----+-----+-----+-------+---------------+---------------+-----------------+-----------------+-----------------+-----------------+---+------+------+-----+-----+-----+-----+----------+-------------+--------------------+\n",
      "|    LCLid|      date|hour|label|month|weekDay|1_diff_energy_t|2_diff_energy_t|1_diff_energy_t_1|2_diff_energy_t_1|1_diff_energy_t_2|2_diff_energy_t_2|rnk|mean_1|mean_2|min_1|max_1|min_2|max_2|Index_Week| categoryWeek|            features|\n",
      "+---------+----------+----+-----+-----+-------+---------------+---------------+-----------------+-----------------+-----------------+-----------------+---+------+------+-----+-----+-----+-----+----------+-------------+--------------------+\n",
      "|MAC005492|2014-02-20|   0|0.357|    2|    Thu|          0.226|           0.35|            0.361|            0.246|            0.385|            0.377|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.226,0.35,0...|\n",
      "|MAC005492|2014-02-20|   1|0.383|    2|    Thu|          0.223|          0.271|            0.226|             0.35|            0.361|            0.246|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.223,0.271,...|\n",
      "|MAC005492|2014-02-20|   2|0.169|    2|    Thu|          0.179|          0.203|            0.223|            0.271|            0.226|             0.35|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.179,0.203,...|\n",
      "|MAC005492|2014-02-20|   3|  0.2|    2|    Thu|          0.187|           0.17|            0.179|            0.203|            0.223|            0.271|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.187,0.17,0...|\n",
      "|MAC005492|2014-02-20|   4|0.172|    2|    Thu|          0.199|          0.197|            0.187|             0.17|            0.179|            0.203|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.199,0.197,...|\n",
      "|MAC005492|2014-02-20|   5|0.238|    2|    Thu|          0.198|          0.195|            0.199|            0.197|            0.187|             0.17|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.198,0.195,...|\n",
      "|MAC005492|2014-02-20|   6|0.172|    2|    Thu|          0.201|          0.199|            0.198|            0.195|            0.199|            0.197|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.201,0.199,...|\n",
      "|MAC005492|2014-02-20|   7|0.212|    2|    Thu|          0.169|          0.171|            0.201|            0.199|            0.198|            0.195|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.169,0.171,...|\n",
      "|MAC005492|2014-02-20|   8|0.302|    2|    Thu|          0.362|          0.265|            0.169|            0.171|            0.201|            0.199|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.362,0.265,...|\n",
      "|MAC005492|2014-02-20|   9|0.303|    2|    Thu|          0.544|          0.449|            0.362|            0.265|            0.169|            0.171|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.544,0.449,...|\n",
      "|MAC005492|2014-02-20|  10|0.187|    2|    Thu|          0.315|          0.259|            0.544|            0.449|            0.362|            0.265|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.315,0.259,...|\n",
      "|MAC005492|2014-02-20|  11| 0.23|    2|    Thu|          0.282|          0.394|            0.315|            0.259|            0.544|            0.449|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.282,0.394,...|\n",
      "|MAC005492|2014-02-20|  12|0.323|    2|    Thu|          0.224|          0.369|            0.282|            0.394|            0.315|            0.259|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.224,0.369,...|\n",
      "|MAC005492|2014-02-20|  13| 0.47|    2|    Thu|            0.3|          0.325|            0.224|            0.369|            0.282|            0.394|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.3,0.325,0....|\n",
      "|MAC005492|2014-02-20|  14|0.209|    2|    Thu|           0.23|          0.458|              0.3|            0.325|            0.224|            0.369|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.23,0.458,0...|\n",
      "|MAC005492|2014-02-20|  15|0.191|    2|    Thu|          0.202|          0.188|             0.23|            0.458|              0.3|            0.325|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.202,0.188,...|\n",
      "|MAC005492|2014-02-20|  16|0.212|    2|    Thu|          0.199|          0.403|            0.202|            0.188|             0.23|            0.458|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.199,0.403,...|\n",
      "|MAC005492|2014-02-20|  17|0.456|    2|    Thu|          0.323|          0.531|            0.199|            0.403|            0.202|            0.188|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.323,0.531,...|\n",
      "|MAC005492|2014-02-20|  18|0.454|    2|    Thu|          0.329|          1.106|            0.323|            0.531|            0.199|            0.403|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.329,1.106,...|\n",
      "|MAC005492|2014-02-20|  19|0.522|    2|    Thu|          0.409|          0.413|            0.329|            1.106|            0.323|            0.531|546|   0.0|   0.0|0.169|0.617| 0.17|1.106|       3.0|(6,[3],[1.0])|[2.0,0.409,0.413,...|\n",
      "+---------+----------+----+-----+-----+-------+---------------+---------------+-----------------+-----------------+-----------------+-----------------+---+------+------+-----+-----+-----+-----+----------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3673.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 1403.0 failed 1 times, most recent failure: Lost task 5.0 in stage 1403.0 (TID 125648, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:77)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12$$anonfun$13.apply(RandomForest.scala:541)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12$$anonfun$13.apply(RandomForest.scala:537)\n\tat scala.Array$.tabulate(Array.scala:331)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12.apply(RandomForest.scala:537)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12.apply(RandomForest.scala:534)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:743)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:742)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:742)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.findBestSplits(RandomForest.scala:563)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:198)\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:130)\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:45)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:77)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12$$anonfun$13.apply(RandomForest.scala:541)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12$$anonfun$13.apply(RandomForest.scala:537)\n\tat scala.Array$.tabulate(Array.scala:331)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12.apply(RandomForest.scala:537)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12.apply(RandomForest.scala:534)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-15808383724c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxDepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumTrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxBins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressionEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetricName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/Spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/lib/Spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/Spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/Spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3673.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 1403.0 failed 1 times, most recent failure: Lost task 5.0 in stage 1403.0 (TID 125648, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:77)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12$$anonfun$13.apply(RandomForest.scala:541)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12$$anonfun$13.apply(RandomForest.scala:537)\n\tat scala.Array$.tabulate(Array.scala:331)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12.apply(RandomForest.scala:537)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12.apply(RandomForest.scala:534)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:743)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$collectAsMap$1.apply(PairRDDFunctions.scala:742)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:742)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.findBestSplits(RandomForest.scala:563)\n\tat org.apache.spark.ml.tree.impl.RandomForest$.run(RandomForest.scala:198)\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:130)\n\tat org.apache.spark.ml.regression.RandomForestRegressor.train(RandomForestRegressor.scala:45)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.ml.tree.impl.DTStatsAggregator.<init>(DTStatsAggregator.scala:77)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12$$anonfun$13.apply(RandomForest.scala:541)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12$$anonfun$13.apply(RandomForest.scala:537)\n\tat scala.Array$.tabulate(Array.scala:331)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12.apply(RandomForest.scala:537)\n\tat org.apache.spark.ml.tree.impl.RandomForest$$anonfun$12.apply(RandomForest.scala:534)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:800)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 50202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/socketserver.py\", line 313, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.5/socketserver.py\", line 341, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.5/socketserver.py\", line 354, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.5/socketserver.py\", line 681, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/lib/Spark/python/pyspark/accumulators.py\", line 235, in handle\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/lib/Spark/python/pyspark/serializers.py\", line 685, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(maxDepth=10, numTrees=10, maxBins=128)\n",
    "rfmodel = rf.fit(train_df)\n",
    "pred_val = rfmodel.transform(test_df)\n",
    "evaluator = RegressionEvaluator(labelCol='label', predictionCol='prediction', metricName=\"rmse\")\n",
    "accuracy = evaluator.evaluate(pred_val)\n",
    "# pred_val.show()\n",
    "print('RMSE = : %.4f'%(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
